{
    "layers": [
        {
            "type": "fully_connected",
            "input_size": 839,
            "output_size": 512
        },
        {
            "type": "activation",
            "activation": "relu"
        },
        {
            "type": "fully_connected",
            "input_size": 512,
            "output_size": 256
        },
        {
            "type": "activation",
            "activation": "relu"
        },
        {
            "type": "fully_connected",
            "input_size": 256,
            "output_size": 2
        }
    ],
    "loss": "cross_entropy"
}
