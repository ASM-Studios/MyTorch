{
    "layers": [
        {
            "type": "fully_connected",
            "input_size": 773,
            "output_size": 512
        },
        {
            "type": "activation",
            "activation": "relu"
        },
        {
            "type": "dropout",
            "rate": 0.5
        },
        {
            "type": "fully_connected",
            "input_size": 512,
            "output_size": 256
        },
        {
            "type": "activation",
            "activation": "relu"
        },
        {
            "type": "dropout",
            "rate": 0.5
        },
        {
            "type": "fully_connected",
            "input_size": 256,
            "output_size": 6
        }
    ],
    "loss": "cross_entropy"
}
